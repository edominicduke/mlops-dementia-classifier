# Import dependencies.
import os
from google.cloud import storage
import pandas as pd
import io

# The following line of code was generated by ChatGPT 5.1 on 11/21/25 at 10:24 PM
from dotenv import load_dotenv

def retrieve_data_as_df():

    # Additional option if built locally via Docker
    if not os.environ.get("GOOGLE_APPLICATION_CREDENTIALS"):
        local_path = "data/processed/cleaned_dementia_dataset.csv"
        print(f"Loading local dataset from {local_path}")
        return pd.read_csv(local_path)
    # Load environment variables.
    load_dotenv()

    # Create a client.
    client = storage.Client()

    # Retrieve the bucket with the cleaned data.
    bucket = client.get_bucket("mlops-dementia-classifier")

    # Retrieve the cleaned data in the bucket.
    data = bucket.get_blob("cleaned_dementia_dataset.csv")

    # Lines 31-33 of code were generated by ChatGPT 5.1 on 11/22/25 at 1:26 PM then modified

    # Download the file bytes of the data and convert to a Pandas DataFrame.
    data_bytes = data.download_as_bytes()
    df = pd.read_csv(io.BytesIO(data_bytes))

    # Return the cleaned data as a pandas DataFrame.
    return df